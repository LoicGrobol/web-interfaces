---
jupyter:
  jupytext:
    formats: ipynb,md
    split_at_heading: true
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.3'
      jupytext_version: 1.14.2
  kernelspec:
    display_name: Python 3 (ipykernel)
    language: python
    name: python3
---

<!-- LTeX: language=fr -->

<!-- #region slideshow={"slide_type": "slide"} -->
Parser des documents balis√©s avec `lxml` et BeautifulSoup‚ÄØ: solutions
=====================================================================

**Lo√Øc Grobol** [<lgrobol@parisnanterre.fr>](mailto:lgrobol@parisnanterre.fr)

<!-- #endregion -->

```python
from IPython.display import display
```

```python
%pip install -U beautifulsoup4 lxml matplotlib requests
```

```python
from bs4 import BeautifulSoup
import lxml
import requests
```

```python
import requests
from bs4 import BeautifulSoup

url = "http://web.archive.org/web/20180430090903/http://songx.se/index.php" # le lien vers le site
html = requests.get(url) # on r√©cup√®re le contenu
soup = BeautifulSoup(html.text, 'lxml') # on cr√©e un objet pour traiter la page
```

## üé∂ Exo 1 üé∂

1\. Affichez les titres et les tunings des 10 premi√®res chansons en utilisant la m√©thode
[`find_all`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#find-all). La m√©thode renvoie un
it√©rable.

```python
for item in soup.find_all('div', attrs={'class':'songrow'})[:10]:
    print(item.a.string, item.div.string)
```

On peut aussi utiliser la notation suivante

```python
for item in soup.find_all('div', class_="songrow")[:10]:
    print(item.a.string, item.div.string)
```

2\. Cr√©ez un `dict` appel√© `tunings` qui classe les chansons par tuning (autrement dit qui associe √†
un tuning la liste des morceaux qui l'utilisent). (On peut utiliser plus sympa qu'un b√™te `dict`).
Lisez bien la doc de
[`find_all`](https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.html#find-all)

```python
from collections import defaultdict
tunings = defaultdict(list)
for item in soup.find_all('div', class_="songrow"):
    song_title = item.a.string
    tuning = item.div.string
    tunings[tuning].append(song_title)
tunings = dict(tunings)
```

(`typing` c'est quoi‚ÄØ? Qu'est-ce que √ßa veut dire `Dict[str, List[str]]`‚ÄØ? On en reparlera si on a le
temps mais vous pouvez prendre de l'avance [sur Real
Python](https://realpython.com/python-type-checking/))

3\. 'Harvest Moon' utilise l'accordage DADGBE, y en a-t'il d'autres ?

```python
tunings["DADGBE"]
```

4\. Affichez les accordages et le nombre de chansons pour chaque accordage, le tout tri√© par nombre de
chansons d√©croissant. Pour cela, cous utiliserez la m√©thode `sorted` ainsi que l'argument mot-cl√©
`key` (des exemples [ici](https://wiki.python.org/moin/HowTo/Sorting#Key_Functions)) :

```python
n_songs = ((tuning, len(songs)) for tuning, songs in tunings.items())
for tuning, n in sorted(n_songs, key=lambda x: -x[1]):
    print(f"{tuning}: {n}")
```

Ou alors

```python
n_songs = ((tuning, len(songs)) for tuning, songs in tunings.items())
for tuning, n in sorted(n_songs, key=lambda x: x[1], reverse=True):
    print(f"{tuning}: {n}")
```

Allez hop un histogramme

```python
%matplotlib inline
import matplotlib.pyplot as plt
values = [len(tunings[x]) for x in tunings]
values
plt.bar(range(0, len(values)), values)
plt.xticks(range(0, len(values)), tunings.keys(), rotation=17)

plt.show()
```

5\. Une chanson a un tuning un peu particulier compar√© aux autres (indice, c'est une question de
taille). Trouvez le tuning qui est diff√©rent des autres et donnez la chanson qui lui correspond.
_Attention_, "b" signifie "b√©mol", il ne s'agit pas d'une note pour l'accordage (contrairement √† A,
B, C, D, E, F et G) !

```python
[t for t in tunings.keys() if len([c for c in t if c.isupper()]) != 6]
```


## Parser du XML

Nous allons travailler sur un fichier au format [TEI](http://www.tei-c.org/) extrait du corpus
[*Corpus 14*](https://hdl.handle.net/11403/corpus14/v1).

Le fichier se nomme [`josephine-1-150119.xml`](data/josephine-1-150119.xml). Il s'agit d'une
lettre d'une femme de soldat √† son √©poux. Les chemins du notebook devraient fonctionner sur Binder,
pour bosser en local, vous pouvez le r√©cup√©rer sur
[GitHub](https://raw.githubusercontent.com/LoicGrobol/web-interfaces/main/data/josephine-1-150119.xml)

Nous allons extraire du fichier TEI les informations suivantes‚ÄØ:

- titre (`/TEI/teiHeader/fileDesc/titleStmt/title`)
- source (`/TEI/teiHeader/fileDesc/sourceDesc/p`)
- contenu de la lettre (`/TEI/text/body`)

Vous pouvez trouver des indications sur les √©l√©ments de la TEI
[ici](http://www.tei-c.org/release/doc/tei-p5-doc/fr/html/) (√ßa pourra √™tre utile pour les
questions)

### Avec lxml

Pourquoi `lxml` et pas `xml.etree.ElementTree` ? Parce que : [1](http://lxml.de/intro.html) et
surtout [2](http://lxml.de/performance.html).

La bonne nouvelle, c'est que votre code sera aussi compatible avec `xml.etree.ElementTree` ou
`xml.etree.cElementTree` parce que xml utilise l'API ElementTree. Sauf pour la m√©thode `xpath` qui
est propre √† `libxml`.

```python
from lxml import etree
tree = etree.parse('data/josephine-1-150119.xml')
root = tree.getroot()

# Parcours des enfants de la racine (commentaires et √©l√©ments)
for child in root:
    print(child.tag)
```

### Avec des requ√™tes `ElementPath`

Le fichier utilise l'[espace de nom](https://fr.wikipedia.org/wiki/Espace_de_noms_XML) TEI : `<TEI
xmlns="http://www.tei-c.org/ns/1.0">`, nous devrons l'indiquer dans nos instructions de recherche.

Nous pouvons r√©cup√©rer un √©l√©ment particulier qui correspond √† un chemin : par exemple, pour
r√©cup√©rer le *header* TEI dont le chemin est `/TEI/teiHeader`

la m√©thode `find` renvoie le premier √©l√©ment qui correspond au chemin argument (`ElementPath` et non
`xpath`)

```python
header = root.find("./tei:teiHeader", namespaces={'tei':"http://www.tei-c.org/ns/1.0"})
header
```

### üß≠ Exo üß≠

1\. R√©cup√©rez le titre et affichez son tag XML ainsi que son contenu textuel (`/TEI/teiHeader/fileDesc/titleStmt/title`)

La m√©thode find renvoie le premier √©l√©ment qui correspond au chemin argument (`ElementPath` et non Xpath)

```python
title = root.find("./tei:teiHeader/tei:fileDesc/tei:titleStmt/tei:title", namespaces={'tei':"http://www.tei-c.org/ns/1.0"})
print(f"Tag : {title.tag}")
print(f"Texte : {title.text}")
```

2\. Idem pour la source (√©l√©ment `sourceDesc`) :

```python
source = root.find("./tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p", namespaces={'tei':"http://www.tei-c.org/ns/1.0"})
print(f"Tag : {title.tag}")
print(f"Texte : {title.text}")
```

### Avec des requ√™tes xpath

`lxml` a aussi une m√©thode [xpath](https://lxml.de/xpathxslt.html) qui permet d'utiliser directement
des [expressions xpath](https://www.w3schools.com/xml/xpath_syntax.asp) (sans oublier les espaces de
noms pour notre fichier)‚ÄØ:

```python
source = root.xpath(
    "/tei:TEI/tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p",
    namespaces={'tei':'http://www.tei-c.org/ns/1.0'},
)
print(f"xpath retourne un objet de type {type(source)}")
print(source[0].text)
```

Ou comme ceci

```python
source = root.xpath(
    "/tei:TEI/tei:teiHeader/tei:fileDesc/tei:sourceDesc/tei:p/text()",
    namespaces={'tei':'http://www.tei-c.org/ns/1.0'},
)
print(source[0])
```

Pour le contenu il faut ruser. La difficult√© ici tient √† l'utilisation d'√©lements `<lb/>` de type
[milestones](http://www.tei-c.org/release/doc/tei-p5-doc/fr/html/CO.html#CORS5) pour noter les
retours √† la ligne :

```xml
<p>
je reponse a ton aimableux lettres<lb/>
que nous a fait plaisir en naprenas<lb/>
que tu et enbonne santes car il<lb/>
anais de maime pour nous<lb/>
</p>
```

### ü•≤ Exo ü•≤

1\. R√©cup√©rez dans un premier temps l'ensemble des balises `<p>` en utilisant la m√©thode
[findall](http://effbot.org/zone/element.htm#searching-for-subelements). la m√©thode `findall`
renvoie une liste avec tous les √©l√©ments correspondant au chemin argument.

```python
body = root.findall("./tei:text/tei:body/tei:p", namespaces={'tei':"http://www.tei-c.org/ns/1.0"})
for elem in body: # tout le texte ne s'affichera pas, c'est normal !
    print(elem.text)
```

Ici on ne r√©cup√®re que les n≈ìuds `text` pr√©c√©dant les √©l√©ments `<lb/>`.

2\. Utilisez la fonction `xpath` pour r√©cup√©rer tous les n≈ìuds texte du corps de la lettre. Vous
int√©grerez dans votre requ√™te la fonction `text` (vue un peu plus haut) dans votre chemin xpath
(vous pouvez *aussi* fouiller [par ici](https://lxml.de/xpathxslt.html) pour avoir de la
documentation suppl√©mentaire).

```python
body = root.xpath("//tei:text/tei:body//text()", namespaces={'tei':"http://www.tei-c.org/ns/1.0"})
for text in body:
    print(text, end="")
```

3\. √âcrivez une requ√™te xpath pour r√©cup√©rer tous les √©l√©ments ratur√©s de la lettre de Jos√©phine.

```python
body = root.xpath("//tei:text/tei:body//tei:del", namespaces={'tei':"http://www.tei-c.org/ns/1.0"})
for text in body:
    print(text, end="")
```


## Avec DOM

L'API `ElementTree` est propre √† Python, `DOM` ([le site officiel](https://www.w3.org/DOM/) et [des
informations en fran√ßais](https://developer.mozilla.org/fr/docs/Web/API/Document_Object_Model)) est
une API ind√©pendante d'un langage de programmation. Il existe des impl√©mentations `DOM` dans la
plupart des langages de programmation modernes.  

```python
from xml.dom import minidom
dom = minidom.parse("data/josephine-1-150119.xml")
dom
```

```python
# un seul √©l√©ment 'title' dans le document
title = dom.getElementsByTagNameNS("http://www.tei-c.org/ns/1.0", 'title')[0]
title
```

`title` est un objet `Element`, pour acc√©der au contenu textuel il faut r√©cup√©rer le n≈ìud texte

```python
print(title) 
print(title.lastChild.nodeName)
print(title.lastChild.nodeValue)
```

Idem pour la source, sauf qu'on ne peut pas se permettre de rechercher tous les √©l√©ments `p`.  
Il faut trouver l'√©l√©ment `p` fils de `sourceDesc`

```python
sourceDesc = dom.getElementsByTagNameNS("http://www.tei-c.org/ns/1.0", 'sourceDesc')[0]
for node in sourceDesc.childNodes:
    if node.localName == "p":
        print(node.lastChild.nodeValue)
```

Et maintenant le contenu et ses √©l√©ments milestones

### üòå Exo üòå

Pour garder la forme, vous r√©√©crirez les boucles `for` suivies de `if` en listes en intension.

```python
body = dom.getElementsByTagNameNS("http://www.tei-c.org/ns/1.0", 'body')[0]
for node in body.childNodes:
    if node.localName in ("p", "opener"):
        for in_node in node.childNodes:
            if in_node.nodeName == "#text":
                print(in_node.nodeValue, end="")
```

```python
body = dom.getElementsByTagNameNS("http://www.tei-c.org/ns/1.0", 'body')[0]
texts = [
    in_node.nodeValue
    for node in body.childNodes
    if node.localName in ("p", "opener")
    for in_node in node.childNodes
    if in_node.nodeName == "#text"
]
for t in texts:
    print(t, end="")
```

## Avec `lxml` et Beautiful Soup

```python
from bs4 import BeautifulSoup

with open("data/josephine-1-150119.xml") as fp:
    soup = BeautifulSoup(fp, 'lxml')
```

```python
soup.title.text
```

```python
soup.sourcedesc.p.text
```

Pour le contenu de la lettre il y a la merveilleuse fonction `get_text()`

```python
soup.get_text?
```

```python
text = soup.find("text")
print(text.getText())
```

`lxml` est rapide, Beautiful Soup simple √† utiliser. Le combo diablement efficace.

Il y a un autre module super pour le web que nous ne verrons pas dans cette s√©ance mais que je me
dois de vous indiquer :¬†[Selenium](https://selenium-python.readthedocs.io/) Selenium va vous
permettre d'automatiser des actions sur un navigateur. Je vous conseille d'essayer, c'est assez
plaisant de voir votre navigateur pilot√© par un script. C'est aussi g√©nial pour tester
automatiquement les interfaces web que vous d√©veloppez

## ü§î Exo d'application ü§î

> Wikipedia trivia: if you take any article, click on the first link in the article text not in
> parentheses or italics, **and then repeat**, you will eventually end up at "Philosophy".  
> ([xkcd #903](https://xkcd.com/903/))

- V√©rifiez sur une page ou deux si c'est vrai
- √âcrivez un script qui prend en argument de ligne de commande un nom de page Wikip√©dia (en anglais,
  sauf si vous aimez l'aventure) et donne le nombre de sauts n√©cessaire pour arriver √† la page
  *Philosophy* ou une erreur si la page en question n'existe pas
- Si vous √™tes tr√®s d√©termin√©‚ãÖe‚ãÖs, faites un script qui prend en entr√©e des pages de Wikip√©dia et
  produit le graphe (orient√©) des pages obtenues en suivant √† chaque fois le premier lien de chaque
  page, et ce jusqu'√† retomber sur une page d√©j√† visit√©e. On pourra par exemple utiliser
  [NetworkX](https://networkx.org/documentation/latest/reference/drawing.html), un visualiseur
  interactif comme [pyvis](https://pyvis.readthedocs.io/en/latest/tutorial.html), [un wrapper de
  graphviz](https://graphviz.readthedocs.io) ou encore g√©n√©rer directement des fichiers dot.
